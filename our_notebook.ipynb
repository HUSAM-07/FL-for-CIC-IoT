{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52777f1d-a960-4b1a-9a67-54f6ebaba326",
   "metadata": {},
   "source": [
    "# Centralised Learning and Federated Learning on the CICIoT2023 dataset\n",
    "\n",
    "This notebook extends on the functionality of the CICIoT2023 example notebook, to account for improvement to the centralised training of all data instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef491788-2e80-4cfc-a86b-556eb4624ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94bf33f7-12e7-4f6e-958b-6b5b0f8b2fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY = 'datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618e631",
   "metadata": {},
   "source": [
    "Include the defines for the dataframe columns and the attack labels and their mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b893d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes import X_columns, y_column, dict_34_classes, dict_8_classes, dict_7_classes, dict_2_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b341488c-b030-4d79-96ac-ef52166f4237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\n",
    "df_sets.sort()\n",
    "\n",
    "# # Create the training and test sets\n",
    "training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "test_sets = df_sets[int(len(df_sets)*.8):]\n",
    "\n",
    "# TODO - REMOVE THIS - Works on 20% of the data for low memory machines\n",
    "# Create the training and test sets - LOW MEMORY CLUDGE FOR JON\n",
    "# training_sets = df_sets[:int(len(df_sets)*.2)]\n",
    "# test_sets = df_sets[int(len(df_sets)*.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde99b74",
   "metadata": {},
   "source": [
    "---\n",
    "# TEMP CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4926641e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HACK TO REPLICATE ORIGINAL AUTHORS CODE WITH ONE FILE TRAIN - ['part-00136-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv']\n"
     ]
    }
   ],
   "source": [
    "# Set training_sets to the last entry of training_sets\n",
    "training_sets = training_sets[-1:]\n",
    "print(f\"HACK TO REPLICATE ORIGINAL AUTHORS CODE WITH ONE FILE TRAIN - {training_sets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1fc92e",
   "metadata": {},
   "source": [
    "Remove this if you have more than a morsel of memory\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d10ad-299a-4741-bed8-dfb6d0a0e6fd",
   "metadata": {},
   "source": [
    "# Create a new DataFrame that consists of all CSV datA\n",
    "\n",
    "This is **memory intensive** as it will create a DataFrame with 36 million rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95c0bce-0698-4e23-b070-3701040ac4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Depreciated method\n",
    "# df = []\n",
    "\n",
    "# count = 0\n",
    "# for train_set in tqdm(training_sets):\n",
    "#     if count == 0:\n",
    "#         df = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "#     else:\n",
    "#         df_new = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "#         df = df.append(df_new, ignore_index=True)\n",
    "#     count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c75f3f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# New faster method not using depreciated pandas append\n",
    "dfs = []\n",
    "for train_set in tqdm(training_sets):\n",
    "    df_new = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "    dfs.append(df_new)\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5c6873b-ece2-4e99-a5a0-bb1733024e06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>Protocol Type</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Srate</th>\n",
       "      <th>Drate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>...</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Magnitue</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Covariance</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025926</td>\n",
       "      <td>56.06</td>\n",
       "      <td>6.00</td>\n",
       "      <td>63.82</td>\n",
       "      <td>3.528480</td>\n",
       "      <td>3.528480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496995</td>\n",
       "      <td>54.20</td>\n",
       "      <td>8.298108e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.405144</td>\n",
       "      <td>0.704371</td>\n",
       "      <td>2.498950</td>\n",
       "      <td>0.10</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DoS-SYN_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>26.996367</td>\n",
       "      <td>26.996367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.308982e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-SYN_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>2.986424</td>\n",
       "      <td>2.986424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.334383e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-RSTFINFlood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.46</td>\n",
       "      <td>5.94</td>\n",
       "      <td>63.36</td>\n",
       "      <td>66.531372</td>\n",
       "      <td>66.531372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131850</td>\n",
       "      <td>54.06</td>\n",
       "      <td>8.309404e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.395650</td>\n",
       "      <td>0.186918</td>\n",
       "      <td>0.195153</td>\n",
       "      <td>0.09</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-SYN_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>10.473893</td>\n",
       "      <td>10.473893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.292583e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DoS-TCP_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444699</th>\n",
       "      <td>0.366179</td>\n",
       "      <td>35971.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>2904.981161</td>\n",
       "      <td>2904.981161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.00</td>\n",
       "      <td>8.309761e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-UDP_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444700</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>2.156362</td>\n",
       "      <td>2.156362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.00</td>\n",
       "      <td>8.312488e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.165151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-ICMP_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444701</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>18.178045</td>\n",
       "      <td>18.178045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.306730e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-TCP_Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444702</th>\n",
       "      <td>1.937804</td>\n",
       "      <td>1935410.08</td>\n",
       "      <td>17.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1762.710435</td>\n",
       "      <td>1762.710435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>554.00</td>\n",
       "      <td>8.378930e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>33.286634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>Mirai-udpplain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444703</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>3.796846</td>\n",
       "      <td>3.796846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8.303414e+07</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>DDoS-TCP_Flood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>444704 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        flow_duration  Header_Length  Protocol Type  Duration         Rate  \\\n",
       "0            0.025926          56.06           6.00     63.82     3.528480   \n",
       "1            0.000000          54.00           6.00     64.00    26.996367   \n",
       "2            0.000000          54.00           6.00     64.00     2.986424   \n",
       "3            0.000000          53.46           5.94     63.36    66.531372   \n",
       "4            0.000000          81.00           6.00     64.00    10.473893   \n",
       "...               ...            ...            ...       ...          ...   \n",
       "444699       0.366179       35971.00          17.00     64.00  2904.981161   \n",
       "444700       0.000000           0.00           1.00     64.00     2.156362   \n",
       "444701       0.000000          54.00           6.00     64.00    18.178045   \n",
       "444702       1.937804     1935410.08          17.00     64.00  1762.710435   \n",
       "444703       0.000000          54.00           6.00     64.00     3.796846   \n",
       "\n",
       "              Srate  Drate  fin_flag_number  syn_flag_number  rst_flag_number  \\\n",
       "0          3.528480    0.0              0.0              1.0              0.0   \n",
       "1         26.996367    0.0              0.0              1.0              0.0   \n",
       "2          2.986424    0.0              1.0              0.0              1.0   \n",
       "3         66.531372    0.0              0.0              1.0              0.0   \n",
       "4         10.473893    0.0              0.0              0.0              0.0   \n",
       "...             ...    ...              ...              ...              ...   \n",
       "444699  2904.981161    0.0              0.0              0.0              0.0   \n",
       "444700     2.156362    0.0              0.0              0.0              0.0   \n",
       "444701    18.178045    0.0              0.0              0.0              0.0   \n",
       "444702  1762.710435    0.0              0.0              0.0              0.0   \n",
       "444703     3.796846    0.0              0.0              0.0              0.0   \n",
       "\n",
       "        ...       Std  Tot size           IAT  Number   Magnitue    Radius  \\\n",
       "0       ...  0.496995     54.20  8.298108e+07     9.5  10.405144  0.704371   \n",
       "1       ...  0.000000     54.00  8.308982e+07     9.5  10.392305  0.000000   \n",
       "2       ...  0.000000     54.00  8.334383e+07     9.5  10.392305  0.000000   \n",
       "3       ...  0.131850     54.06  8.309404e+07     9.5  10.395650  0.186918   \n",
       "4       ...  0.000000     54.00  8.292583e+07     9.5  10.392305  0.000000   \n",
       "...     ...       ...       ...           ...     ...        ...       ...   \n",
       "444699  ...  0.000000     50.00  8.309761e+07     9.5  10.000000  0.000000   \n",
       "444700  ...  0.000000     42.00  8.312488e+07     9.5   9.165151  0.000000   \n",
       "444701  ...  0.000000     54.00  8.306730e+07     9.5  10.392305  0.000000   \n",
       "444702  ...  0.000000    554.00  8.378930e+07     9.5  33.286634  0.000000   \n",
       "444703  ...  0.000000     54.00  8.303414e+07     9.5  10.392305  0.000000   \n",
       "\n",
       "        Covariance  Variance  Weight             label  \n",
       "0         2.498950      0.10  141.55     DoS-SYN_Flood  \n",
       "1         0.000000      0.00  141.55    DDoS-SYN_Flood  \n",
       "2         0.000000      0.00  141.55  DDoS-RSTFINFlood  \n",
       "3         0.195153      0.09  141.55    DDoS-SYN_Flood  \n",
       "4         0.000000      0.00  141.55     DoS-TCP_Flood  \n",
       "...            ...       ...     ...               ...  \n",
       "444699    0.000000      0.00  141.55    DDoS-UDP_Flood  \n",
       "444700    0.000000      0.00  141.55   DDoS-ICMP_Flood  \n",
       "444701    0.000000      0.00  141.55    DDoS-TCP_Flood  \n",
       "444702    0.000000      0.00  141.55    Mirai-udpplain  \n",
       "444703    0.000000      0.00  141.55    DDoS-TCP_Flood  \n",
       "\n",
       "[444704 rows x 47 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08029a2f",
   "metadata": {},
   "source": [
    "## Map the y labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6ed9fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map y column to the dict_34_classes values\n",
    "df['label'] = df['label'].map(dict_34_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edb73a9-e0e6-44b2-8ad5-291e42fc3f0c",
   "metadata": {},
   "source": [
    "# Save this output to a Pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dafe71b-84f3-4dea-b906-a4fe31f31ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_pickle('training_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f819a842-d247-4b52-9e87-1d55b2d173e1",
   "metadata": {},
   "source": [
    "We can now retrieve the dataset from the pkl in further work (pickle file approx 2GB compared to 12GB of CSV data).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41888ad",
   "metadata": {},
   "source": [
    "# Read the pickle file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e109b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pickle file\n",
    "df = pd.read_pickle('training_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30fdf1-6d0c-4a1a-8cea-0a6ae53288f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scale the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae08745b-9b58-4fad-8754-7051afed7b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df[X_columns] = scaler.fit_transform(df[X_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f18dd-f569-4c67-a320-54f5a2d1360a",
   "metadata": {},
   "source": [
    "# Classification Problem (2-class, 8-class, or 34-class)\n",
    "Select which size classification problem you want to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99c225c6-a510-4652-bd04-2a6027743158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary 2 Class Classifier...\n"
     ]
    }
   ],
   "source": [
    "binary_classifier = True\n",
    "group_classifier = False\n",
    "individual_classifier = False\n",
    "\n",
    "if group_classifier:\n",
    "    print(\"Group 8 Class Classifier...\")\n",
    "    # Map y column to the dict_7_classes values\n",
    "    df['label'] = df['label'].map(dict_8_classes)\n",
    "    class_size = \"8\"\n",
    "        \n",
    "elif binary_classifier:\n",
    "    print(\"Binary 2 Class Classifier...\")\n",
    "    # Map y column to the dict_2_classes values\n",
    "    df['label'] = df['label'].map(dict_2_classes)\n",
    "    class_size = \"2\"\n",
    "\n",
    "else:\n",
    "    print (\"Individual 34 Class classifier...\")\n",
    "    class_size = \"34\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc76b81-34a2-4db2-84e9-664f4ea99ecd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Creation (LR, RF, MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "970ab1fc-d4d4-4394-88b0-85ce92992c71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-01 09:13:44.741381  : Fit LogisticRegression model...\n",
      "2024-05-01 09:13:50.522883  : Fit LogisticRegression model complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:54<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### LogisticRegression (2 classes) #####\n",
      "accuracy_score:  0.9888853379374651\n",
      "recall_score:  0.8882461614760764\n",
      "precision_score:  0.8623430643500973\n",
      "f1_score:  0.8748222701094408\n",
      "\n",
      "\n",
      "2024-05-01 09:15:14.786857  : Fit RandomForestClassifier model...\n",
      "2024-05-01 09:15:51.973362  : Fit RandomForestClassifier model complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:25<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### RandomForestClassifier (2 classes) #####\n",
      "accuracy_score:  0.9970649073646985\n",
      "recall_score:  0.9643603701206325\n",
      "precision_score:  0.9723476381512665\n",
      "f1_score:  0.9683181534689906\n",
      "\n",
      "\n",
      "2024-05-01 09:17:47.106997  : Fit MLPClassifier model...\n",
      "2024-05-01 09:19:42.845142  : Fit MLPClassifier model complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:09<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### MLPClassifier (2 classes) #####\n",
      "accuracy_score:  0.993780921670039\n",
      "recall_score:  0.9240563284796784\n",
      "precision_score:  0.944157769101246\n",
      "f1_score:  0.9338613592092939\n",
      "\n",
      "\n",
      "CPU times: total: 4min 11s\n",
      "Wall time: 7min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "ML_models = [\n",
    "    (\"LogisticRegression\", LogisticRegression(n_jobs=-1), f\"logreg-{class_size}class-model.pkl\"),\n",
    "    (\"RandomForestClassifier\", RandomForestClassifier(), f\"rf-{class_size}class-model.pkl\"),\n",
    "    (\"MLPClassifier\", MLPClassifier(), f\"mlp-{class_size}class-model.pkl\")\n",
    "]\n",
    "\n",
    "def train_and_evaluate(name, model, model_file, df):\n",
    "    print(datetime.now(), f\" : Fit {name} model...\")\n",
    "    model.fit(df[X_columns], df[y_column])\n",
    "    print(datetime.now(), f\" : Fit {name} model complete...\")\n",
    "    \n",
    "    with open(model_file, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    y_test = []\n",
    "    preds = []\n",
    "    for test_set in tqdm(test_sets):\n",
    "        d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "        d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "\n",
    "        # Always map the y column to the dict_34_classes values\n",
    "        new_y = [dict_34_classes[k] for k in d_test[y_column]]\n",
    "        d_test[y_column] = new_y\n",
    "\n",
    "        if binary_classifier:\n",
    "            # binary classifier (2-class)\n",
    "            new_y = [dict_2_classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "        elif group_classifier:\n",
    "            # group classifier (8-class)\n",
    "            new_y = [dict_8_classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "        else:\n",
    "            # individual_classifier\n",
    "            pass\n",
    "\n",
    "        y_test += list(d_test[y_column].values)\n",
    "\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        preds += y_pred\n",
    "\n",
    "    print(f\"##### {name} ({class_size} classes) #####\")\n",
    "    print('accuracy_score: ', accuracy_score(preds, y_test))\n",
    "    print('recall_score: ', recall_score(preds, y_test, average='macro'))\n",
    "    print('precision_score: ', precision_score(preds, y_test, average='macro'))\n",
    "    print('f1_score: ', f1_score(preds, y_test, average='macro'))\n",
    "    print('\\n')\n",
    "\n",
    "for name, model, model_file in ML_models:\n",
    "    train_and_evaluate(name, model, model_file, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9984dd7-6601-49ea-94be-d9882ac4b439",
   "metadata": {},
   "source": [
    "# Load in a Pickled model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bd1c099-824b-4111-b174-7f662ee7001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_data.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f241ec19-4db5-4fa0-8640-15f334a7d7f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate Test Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1632303c-d95a-4461-b3e8-0eff5ae64a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Mirai-greip_flood'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m d_test[X_columns] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(d_test[X_columns])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binary_classifier:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# binary classifier (2-class)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     new_y \u001b[38;5;241m=\u001b[39m [dict_2_classes[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m d_test[y_column]]\n\u001b[0;32m     10\u001b[0m     d_test[y_column] \u001b[38;5;241m=\u001b[39m new_y\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m group_classifier:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# group classifier (8-class)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m d_test[X_columns] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(d_test[X_columns])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binary_classifier:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# binary classifier (2-class)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     new_y \u001b[38;5;241m=\u001b[39m [\u001b[43mdict_2_classes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m d_test[y_column]]\n\u001b[0;32m     10\u001b[0m     d_test[y_column] \u001b[38;5;241m=\u001b[39m new_y\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m group_classifier:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# group classifier (8-class)\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Mirai-greip_flood'"
     ]
    }
   ],
   "source": [
    "y_test = []\n",
    "preds = {i:[] for i in range(len(ML_models))}\n",
    "for test_set in tqdm(test_sets):\n",
    "    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "    d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "\n",
    "    if binary_classifier:\n",
    "        # binary classifier (2-class)\n",
    "        new_y = [dict_2_classes[k] for k in d_test[y_column]]\n",
    "        d_test[y_column] = new_y\n",
    "\n",
    "\n",
    "    elif group_classifier:\n",
    "        # group classifier (8-class)\n",
    "        new_y = [dict_7_classes[k] for k in d_test[y_column]]\n",
    "        d_test[y_column] = new_y\n",
    "\n",
    "    else:\n",
    "        # individual_classifier\n",
    "        pass\n",
    "\n",
    "    y_test += list(d_test[y_column].values)\n",
    "\n",
    "    y_pred = list(model.predict(d_test[X_columns]))\n",
    "    preds[0] = preds[0] + y_pred\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "for k,v in preds.items():\n",
    "    y_pred = v\n",
    "    print(f\"##### {ML_names[k]} (34 classes) #####\")\n",
    "    print('accuracy_score: ', accuracy_score(y_pred, y_test))\n",
    "    print('recall_score: ', recall_score(y_pred, y_test, average='macro'))\n",
    "    print('precision_score: ', precision_score(y_pred, y_test, average='macro'))\n",
    "    print('f1_score: ', f1_score(y_pred, y_test, average='macro'))\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
